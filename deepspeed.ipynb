{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Installation\n",
    "\n",
    "create conda env\n",
    "```bash\n",
    "conda create -c conda-forge  -c pytorch -c nvidia --name ds \\\n",
    "python=3.9 pytorch pytorch-cuda=11.7\n",
    "```\n",
    "\n",
    "activate environment\n",
    "`conda activate ds`\n",
    "\n",
    "install jupyter\n",
    "`pip install jupyter`\n",
    "\n",
    "11.6\n",
    "\n",
    "conda create --channel=conda-forge --name ds \\\n",
    "  python=3.9 \\\n",
    "  nvidia::cudatoolkit=11.6 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu116\n",
      "Collecting torch==1.12.1\n",
      "  Downloading https://download.pytorch.org/whl/cu116/torch-1.12.1%2Bcu116-cp39-cp39-linux_x86_64.whl (1904.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 GB\u001b[0m \u001b[31m359.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:01\u001b[0m00:02\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/envs/ds/lib/python3.9/site-packages (from torch==1.12.1) (4.4.0)\n",
      "Installing collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.13.1.post200\n",
      "    Uninstalling torch-1.13.1.post200:\n",
      "      Successfully uninstalled torch-1.13.1.post200\n",
      "Successfully installed torch-1.12.1+cu116\n",
      "Requirement already satisfied: deepspeed[sd] in /opt/conda/envs/ds/lib/python3.9/site-packages (0.7.7)\n",
      "Requirement already satisfied: deepspeed-mii in /opt/conda/envs/ds/lib/python3.9/site-packages (0.0.4)\n",
      "Requirement already satisfied: py-cpuinfo in /opt/conda/envs/ds/lib/python3.9/site-packages (from deepspeed[sd]) (9.0.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/ds/lib/python3.9/site-packages (from deepspeed[sd]) (1.24.1)\n",
      "Requirement already satisfied: pydantic in /opt/conda/envs/ds/lib/python3.9/site-packages (from deepspeed[sd]) (1.10.4)\n",
      "Requirement already satisfied: hjson in /opt/conda/envs/ds/lib/python3.9/site-packages (from deepspeed[sd]) (3.1.0)\n",
      "Requirement already satisfied: ninja in /opt/conda/envs/ds/lib/python3.9/site-packages (from deepspeed[sd]) (1.11.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/ds/lib/python3.9/site-packages (from deepspeed[sd]) (23.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/envs/ds/lib/python3.9/site-packages (from deepspeed[sd]) (5.9.4)\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/ds/lib/python3.9/site-packages (from deepspeed[sd]) (4.64.1)\n",
      "Requirement already satisfied: torch in /opt/conda/envs/ds/lib/python3.9/site-packages (from deepspeed[sd]) (1.12.1+cu116)\n",
      "Requirement already satisfied: triton==2.0.0.dev20221005 in /opt/conda/envs/ds/lib/python3.9/site-packages (from deepspeed[sd]) (2.0.0.dev20221005)\n",
      "Requirement already satisfied: diffusers in /opt/conda/envs/ds/lib/python3.9/site-packages (from deepspeed[sd]) (0.11.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/ds/lib/python3.9/site-packages (from triton==2.0.0.dev20221005->deepspeed[sd]) (3.9.0)\n",
      "Requirement already satisfied: cmake in /opt/conda/envs/ds/lib/python3.9/site-packages (from triton==2.0.0.dev20221005->deepspeed[sd]) (3.25.0)\n",
      "Requirement already satisfied: asyncio in /opt/conda/envs/ds/lib/python3.9/site-packages (from deepspeed-mii) (3.4.3)\n",
      "Requirement already satisfied: grpcio-tools in /opt/conda/envs/ds/lib/python3.9/site-packages (from deepspeed-mii) (1.51.1)\n",
      "Requirement already satisfied: transformers in /opt/conda/envs/ds/lib/python3.9/site-packages (from deepspeed-mii) (4.25.1)\n",
      "Requirement already satisfied: grpcio in /opt/conda/envs/ds/lib/python3.9/site-packages (from deepspeed-mii) (1.51.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/envs/ds/lib/python3.9/site-packages (from diffusers->deepspeed[sd]) (2022.10.31)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/envs/ds/lib/python3.9/site-packages (from diffusers->deepspeed[sd]) (6.0.0)\n",
      "Requirement already satisfied: Pillow in /opt/conda/envs/ds/lib/python3.9/site-packages (from diffusers->deepspeed[sd]) (9.4.0)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/ds/lib/python3.9/site-packages (from diffusers->deepspeed[sd]) (2.28.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.10.0 in /opt/conda/envs/ds/lib/python3.9/site-packages (from diffusers->deepspeed[sd]) (0.11.1)\n",
      "Requirement already satisfied: protobuf<5.0dev,>=4.21.6 in /opt/conda/envs/ds/lib/python3.9/site-packages (from grpcio-tools->deepspeed-mii) (4.21.12)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/ds/lib/python3.9/site-packages (from grpcio-tools->deepspeed-mii) (66.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/envs/ds/lib/python3.9/site-packages (from pydantic->deepspeed[sd]) (4.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/ds/lib/python3.9/site-packages (from transformers->deepspeed-mii) (6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/envs/ds/lib/python3.9/site-packages (from transformers->deepspeed-mii) (0.13.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/ds/lib/python3.9/site-packages (from importlib-metadata->diffusers->deepspeed[sd]) (3.11.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/ds/lib/python3.9/site-packages (from requests->diffusers->deepspeed[sd]) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/ds/lib/python3.9/site-packages (from requests->diffusers->deepspeed[sd]) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/ds/lib/python3.9/site-packages (from requests->diffusers->deepspeed[sd]) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/ds/lib/python3.9/site-packages (from requests->diffusers->deepspeed[sd]) (3.0.1)\n",
      "Collecting diffusers==0.6.0\n",
      "  Downloading diffusers-0.6.0-py3-none-any.whl (255 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.4/255.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: triton==2.0.0.dev20221005 in /opt/conda/envs/ds/lib/python3.9/site-packages (2.0.0.dev20221005)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/envs/ds/lib/python3.9/site-packages (from diffusers==0.6.0) (2022.10.31)\n",
      "Requirement already satisfied: Pillow<10.0 in /opt/conda/envs/ds/lib/python3.9/site-packages (from diffusers==0.6.0) (9.4.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.10.0 in /opt/conda/envs/ds/lib/python3.9/site-packages (from diffusers==0.6.0) (0.11.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/envs/ds/lib/python3.9/site-packages (from diffusers==0.6.0) (6.0.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/ds/lib/python3.9/site-packages (from diffusers==0.6.0) (3.9.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/ds/lib/python3.9/site-packages (from diffusers==0.6.0) (1.24.1)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/ds/lib/python3.9/site-packages (from diffusers==0.6.0) (2.28.2)\n",
      "Requirement already satisfied: cmake in /opt/conda/envs/ds/lib/python3.9/site-packages (from triton==2.0.0.dev20221005) (3.25.0)\n",
      "Requirement already satisfied: torch in /opt/conda/envs/ds/lib/python3.9/site-packages (from triton==2.0.0.dev20221005) (1.12.1+cu116)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/ds/lib/python3.9/site-packages (from huggingface-hub>=0.10.0->diffusers==0.6.0) (6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/envs/ds/lib/python3.9/site-packages (from huggingface-hub>=0.10.0->diffusers==0.6.0) (23.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/envs/ds/lib/python3.9/site-packages (from huggingface-hub>=0.10.0->diffusers==0.6.0) (4.4.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/ds/lib/python3.9/site-packages (from huggingface-hub>=0.10.0->diffusers==0.6.0) (4.64.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/ds/lib/python3.9/site-packages (from importlib-metadata->diffusers==0.6.0) (3.11.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/ds/lib/python3.9/site-packages (from requests->diffusers==0.6.0) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/ds/lib/python3.9/site-packages (from requests->diffusers==0.6.0) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/ds/lib/python3.9/site-packages (from requests->diffusers==0.6.0) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/ds/lib/python3.9/site-packages (from requests->diffusers==0.6.0) (2022.12.7)\n",
      "Installing collected packages: diffusers\n",
      "  Attempting uninstall: diffusers\n",
      "    Found existing installation: diffusers 0.11.1\n",
      "    Uninstalling diffusers-0.11.1:\n",
      "      Successfully uninstalled diffusers-0.11.1\n",
      "Successfully installed diffusers-0.6.0\n",
      "Collecting transformers[sentencepiece]==4.24.0\n",
      "  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: accelerate in /opt/conda/envs/ds/lib/python3.9/site-packages (0.15.0)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/ds/lib/python3.9/site-packages (from transformers[sentencepiece]==4.24.0) (2.28.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/ds/lib/python3.9/site-packages (from transformers[sentencepiece]==4.24.0) (6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /opt/conda/envs/ds/lib/python3.9/site-packages (from transformers[sentencepiece]==4.24.0) (0.11.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/envs/ds/lib/python3.9/site-packages (from transformers[sentencepiece]==4.24.0) (2022.10.31)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/ds/lib/python3.9/site-packages (from transformers[sentencepiece]==4.24.0) (3.9.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/envs/ds/lib/python3.9/site-packages (from transformers[sentencepiece]==4.24.0) (4.64.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/envs/ds/lib/python3.9/site-packages (from transformers[sentencepiece]==4.24.0) (23.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/envs/ds/lib/python3.9/site-packages (from transformers[sentencepiece]==4.24.0) (0.13.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/envs/ds/lib/python3.9/site-packages (from transformers[sentencepiece]==4.24.0) (1.24.1)\n",
      "Collecting protobuf<=3.20.2\n",
      "  Downloading protobuf-3.20.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting sentencepiece!=0.1.92,>=0.1.91\n",
      "  Downloading sentencepiece-0.1.97-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.4.0 in /opt/conda/envs/ds/lib/python3.9/site-packages (from accelerate) (1.12.1+cu116)\n",
      "Requirement already satisfied: psutil in /opt/conda/envs/ds/lib/python3.9/site-packages (from accelerate) (5.9.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/envs/ds/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers[sentencepiece]==4.24.0) (4.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/ds/lib/python3.9/site-packages (from requests->transformers[sentencepiece]==4.24.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/ds/lib/python3.9/site-packages (from requests->transformers[sentencepiece]==4.24.0) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/ds/lib/python3.9/site-packages (from requests->transformers[sentencepiece]==4.24.0) (3.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/ds/lib/python3.9/site-packages (from requests->transformers[sentencepiece]==4.24.0) (2022.12.7)\n",
      "Installing collected packages: sentencepiece, protobuf, transformers\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.21.12\n",
      "    Uninstalling protobuf-4.21.12:\n",
      "      Successfully uninstalled protobuf-4.21.12\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.25.1\n",
      "    Uninstalling transformers-4.25.1:\n",
      "      Successfully uninstalled transformers-4.25.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "grpcio-tools 1.51.1 requires protobuf<5.0dev,>=4.21.6, but you have protobuf 3.20.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed protobuf-3.20.2 sentencepiece-0.1.97 transformers-4.24.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.12.1 --extra-index-url https://download.pytorch.org/whl/cu116 --upgrade\n",
    "!pip install deepspeed[sd] deepspeed-mii --upgrade\n",
    "!pip install accelerate --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting deepspeed_requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile deepspeed_requirements.txt\n",
    "deepspeed[sd] \n",
    "deepspeed-mii\n",
    "accelerate\n",
    "ninja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting deepspeed[sd]\n",
      "  Using cached deepspeed-0.7.7-py3-none-any.whl\n",
      "Collecting deepspeed-mii\n",
      "  Using cached deepspeed_mii-0.0.4-py3-none-any.whl (44 kB)\n",
      "Collecting accelerate\n",
      "  Using cached accelerate-0.15.0-py3-none-any.whl (191 kB)\n",
      "Collecting ninja\n",
      "  Using cached ninja-1.11.1-py2.py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (145 kB)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pydantic\n",
      "  Downloading pydantic-1.10.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: psutil in /opt/conda/envs/ds/lib/python3.9/site-packages (from deepspeed[sd]->-r deepspeed_requirements.txt (line 1)) (5.9.4)\n",
      "Collecting py-cpuinfo\n",
      "  Using cached py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Collecting hjson\n",
      "  Using cached hjson-3.1.0-py3-none-any.whl (54 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/ds/lib/python3.9/site-packages (from deepspeed[sd]->-r deepspeed_requirements.txt (line 1)) (23.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/ds/lib/python3.9/site-packages (from deepspeed[sd]->-r deepspeed_requirements.txt (line 1)) (1.24.1)\n",
      "Requirement already satisfied: torch in /opt/conda/envs/ds/lib/python3.9/site-packages (from deepspeed[sd]->-r deepspeed_requirements.txt (line 1)) (1.13.1.post200)\n",
      "Collecting diffusers\n",
      "  Using cached diffusers-0.11.1-py3-none-any.whl (524 kB)\n",
      "Collecting triton==2.0.0.dev20221005\n",
      "  Using cached triton-2.0.0.dev20221005-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.7 MB)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.9.0-py3-none-any.whl (9.7 kB)\n",
      "Collecting cmake\n",
      "  Using cached cmake-3.25.0-py2.py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23.7 MB)\n",
      "Collecting grpcio\n",
      "  Using cached grpcio-1.51.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "Collecting asyncio\n",
      "  Using cached asyncio-3.4.3-py3-none-any.whl (101 kB)\n",
      "Collecting grpcio-tools\n",
      "  Using cached grpcio_tools-1.51.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/envs/ds/lib/python3.9/site-packages (from accelerate->-r deepspeed_requirements.txt (line 3)) (6.0)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/envs/ds/lib/python3.9/site-packages (from torch->deepspeed[sd]->-r deepspeed_requirements.txt (line 1)) (4.4.0)\n",
      "Collecting requests\n",
      "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata in /opt/conda/envs/ds/lib/python3.9/site-packages (from diffusers->deepspeed[sd]->-r deepspeed_requirements.txt (line 1)) (6.0.0)\n",
      "Collecting regex!=2019.12.17\n",
      "  Using cached regex-2022.10.31-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (769 kB)\n",
      "Collecting Pillow\n",
      "  Downloading Pillow-9.4.0-cp39-cp39-manylinux_2_28_x86_64.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub>=0.10.0\n",
      "  Using cached huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/ds/lib/python3.9/site-packages (from grpcio-tools->deepspeed-mii->-r deepspeed_requirements.txt (line 2)) (66.0.0)\n",
      "Collecting protobuf<5.0dev,>=4.21.6\n",
      "  Using cached protobuf-4.21.12-cp37-abi3-manylinux2014_x86_64.whl (409 kB)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Using cached tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/ds/lib/python3.9/site-packages (from importlib-metadata->diffusers->deepspeed[sd]->-r deepspeed_requirements.txt (line 1)) (3.11.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/ds/lib/python3.9/site-packages (from requests->diffusers->deepspeed[sd]->-r deepspeed_requirements.txt (line 1)) (3.4)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (198 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.8/198.8 kB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting certifi>=2017.4.17\n",
      "  Downloading certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tokenizers, py-cpuinfo, ninja, hjson, cmake, charset-normalizer, asyncio, urllib3, tqdm, regex, pydantic, protobuf, Pillow, grpcio, filelock, certifi, triton, requests, grpcio-tools, deepspeed, accelerate, huggingface-hub, transformers, diffusers, deepspeed-mii\n",
      "Successfully installed Pillow-9.4.0 accelerate-0.15.0 asyncio-3.4.3 certifi-2022.12.7 charset-normalizer-3.0.1 cmake-3.25.0 deepspeed-0.7.7 deepspeed-mii-0.0.4 diffusers-0.11.1 filelock-3.9.0 grpcio-1.51.1 grpcio-tools-1.51.1 hjson-3.1.0 huggingface-hub-0.11.1 ninja-1.11.1 protobuf-4.21.12 py-cpuinfo-9.0.0 pydantic-1.10.4 regex-2022.10.31 requests-2.28.2 tokenizers-0.13.2 tqdm-4.64.1 transformers-4.25.1 triton-2.0.0.dev20221005 urllib3-1.26.14\n"
     ]
    }
   ],
   "source": [
    "!pip install -r deepspeed_requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "DeepSpeed C++/CUDA extension op report\n",
      "--------------------------------------------------\n",
      "NOTE: Ops not installed will be just-in-time (JIT) compiled at\n",
      "      runtime if needed. Op compatibility means that your system\n",
      "      meet the required dependencies to JIT install the op.\n",
      "--------------------------------------------------\n",
      "JIT compiled ops requires ninja\n",
      "ninja .................. \u001b[92m[OKAY]\u001b[0m\n",
      "--------------------------------------------------\n",
      "op name ................ installed .. compatible\n",
      "--------------------------------------------------\n",
      "cpu_adam ............... \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
      "cpu_adagrad ............ \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
      "fused_adam ............. \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
      "fused_lamb ............. \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
      "\u001b[93m [WARNING] \u001b[0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible\n",
      "sparse_attn ............ \u001b[93m[NO]\u001b[0m ....... \u001b[93m[NO]\u001b[0m\n",
      "transformer ............ \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
      "stochastic_transformer . \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
      "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
      "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
      "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
      "async_io ............... \u001b[93m[NO]\u001b[0m ....... \u001b[93m[NO]\u001b[0m\n",
      "utils .................. \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
      "quantizer .............. \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
      "transformer_inference .. \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
      "spatial_inference ...... \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
      "--------------------------------------------------\n",
      "DeepSpeed general environment info:\n",
      "torch install path ............... ['/opt/conda/envs/ds/lib/python3.9/site-packages/torch']\n",
      "torch version .................... 1.12.1+cu116\n",
      "torch cuda version ............... 11.6\n",
      "torch hip version ................ None\n",
      "nvcc version ..................... 11.7\n",
      "deepspeed install path ........... ['/opt/conda/envs/ds/lib/python3.9/site-packages/deepspeed']\n",
      "deepspeed info ................... 0.7.7, unknown, unknown\n",
      "deepspeed wheel compiled w. ...... torch 1.13, cuda 11.7\n"
     ]
    }
   ],
   "source": [
    "!ds_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2022 NVIDIA Corporation\n",
      "Built on Wed_Jun__8_16:49:14_PDT_2022\n",
      "Cuda compilation tools, release 11.7, V11.7.99\n",
      "Build cuda_11.7.r11.7/compiler.31442593_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-01-17 18:00:10,930] [INFO] [deployment.py:87:deploy] ************* MII is using DeepSpeed Optimizations to accelerate your model *************\n",
      "[2023-01-17 18:00:11,007] [INFO] [server_client.py:219:_initialize_service] MII using multi-gpu deepspeed launcher:\n",
      " ------------------------------------------------------------\n",
      " task-name .................... text-to-image \n",
      " model ........................ runwayml/stable-diffusion-v1-5 \n",
      " model-path ................... /tmp/mii_models \n",
      " port ......................... 50050 \n",
      " provider ..................... diffusers \n",
      " ------------------------------------------------------------\n",
      "[2023-01-17 18:00:12,269] [WARNING] [runner.py:179:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n",
      "[2023-01-17 18:00:12,299] [INFO] [runner.py:508:main] cmd = /opt/conda/envs/ds/bin/python3.9 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 --no_python --no_local_rank /opt/conda/envs/ds/bin/python -m mii.launch.multi_gpu_server --task-name text-to-image --model runwayml/stable-diffusion-v1-5 --model-path /tmp/mii_models --port 50050 --ds-optimize --provider diffusers --config eyJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAicG9ydF9udW1iZXIiOiA1MDA1MCwgImR0eXBlIjogInRvcmNoLmZsb2F0MTYiLCAibG9hZF93aXRoX3N5c19tZW0iOiBmYWxzZSwgImVuYWJsZV9jdWRhX2dyYXBoIjogZmFsc2UsICJjaGVja3BvaW50X2RpY3QiOiBudWxsLCAiZGVwbG95X3JhbmsiOiBbMF0sICJ0b3JjaF9kaXN0X3BvcnQiOiAyOTUwMCwgImhmX2F1dGhfdG9rZW4iOiBudWxsLCAicmVwbGFjZV93aXRoX2tlcm5lbF9pbmplY3QiOiB0cnVlLCAicHJvZmlsZV9tb2RlbF90aW1lIjogZmFsc2UsICJza2lwX21vZGVsX2NoZWNrIjogZmFsc2V9\n",
      "[2023-01-17 18:00:13,521] [INFO] [launch.py:142:main] WORLD INFO DICT: {'localhost': [0]}\n",
      "[2023-01-17 18:00:13,521] [INFO] [launch.py:148:main] nnodes=1, num_local_procs=1, node_rank=0\n",
      "[2023-01-17 18:00:13,521] [INFO] [launch.py:161:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})\n",
      "[2023-01-17 18:00:13,521] [INFO] [launch.py:162:main] dist_world_size=1\n",
      "[2023-01-17 18:00:13,521] [INFO] [launch.py:164:main] Setting CUDA_VISIBLE_DEVICES=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 15 files: 100%|██████████| 15/15 [00:00<00:00, 31952.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-01-17 18:00:16,022] [INFO] [server_client.py:117:_wait_until_server_is_live] waiting for server to start...\n",
      "[2023-01-17 18:00:21,028] [INFO] [server_client.py:117:_wait_until_server_is_live] waiting for server to start...\n",
      "[2023-01-17 18:00:26,034] [INFO] [server_client.py:117:_wait_until_server_is_live] waiting for server to start...\n",
      "[2023-01-17 18:00:31,039] [INFO] [server_client.py:117:_wait_until_server_is_live] waiting for server to start...\n",
      "[2023-01-17 18:00:36,044] [INFO] [server_client.py:117:_wait_until_server_is_live] waiting for server to start...\n",
      "[2023-01-17 18:00:41,049] [INFO] [server_client.py:117:_wait_until_server_is_live] waiting for server to start...\n",
      "[2023-01-17 18:00:46,054] [INFO] [server_client.py:117:_wait_until_server_is_live] waiting for server to start...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The config attributes {'clip_sample': False} were passed to PNDMScheduler, but are not expected and will be ignored. Please verify your scheduler_config.json configuration file.\n",
      "ftfy or spacy is not installed using BERT BasicTokenizer instead of ftfy.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> --------- MII Settings: ds_optimize=True, replace_with_kernel_inject=True, enable_cuda_graph=False \n",
      "[2023-01-17 18:00:50,919] [INFO] [logging.py:68:log_dist] [Rank -1] DeepSpeed info: version=0.7.7, git-hash=unknown, git-branch=unknown\n",
      "[2023-01-17 18:00:50,920] [INFO] [logging.py:68:log_dist] [Rank -1] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1\n",
      "**** found and replaced vae w. <class 'deepspeed.model_implementations.diffusers.vae.DSVAE'>\n",
      "[2023-01-17 18:00:51,057] [INFO] [server_client.py:117:_wait_until_server_is_live] waiting for server to start...\n",
      "Installed CUDA version 11.7 does not match the version torch was compiled with 11.6 but since the APIs are compatible, accepting this combination\n",
      "Using /home/ubuntu/.cache/torch_extensions/py39_cu116 as PyTorch extensions root...\n",
      "Creating extension directory /home/ubuntu/.cache/torch_extensions/py39_cu116/transformer_inference...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py39_cu116/transformer_inference/build.ninja...\n",
      "Building extension module transformer_inference...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "[1/9] /opt/conda/envs/ds/bin/nvcc  -DTORCH_EXTENSION_NAME=transformer_inference -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/opt/conda/envs/ds/lib/python3.9/site-packages/deepspeed/ops/csrc/transformer/inference/includes -I/opt/conda/envs/ds/lib/python3.9/site-packages/deepspeed/ops/csrc/includes -isystem /opt/conda/envs/ds/lib/python3.9/site-packages/torch/include -isystem /opt/conda/envs/ds/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/envs/ds/lib/python3.9/site-packages/torch/include/TH -isystem /opt/conda/envs/ds/lib/python3.9/site-packages/torch/include/THC -isystem /opt/conda/envs/ds/include -isystem /opt/conda/envs/ds/include/python3.9 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_86,code=compute_86 -c /opt/conda/envs/ds/lib/python3.9/site-packages/deepspeed/ops/csrc/transformer/inference/csrc/softmax.cu -o softmax.cuda.o \n",
      "\u001b[31mFAILED: \u001b[0msoftmax.cuda.o \n",
      "/opt/conda/envs/ds/bin/nvcc  -DTORCH_EXTENSION_NAME=transformer_inference -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/opt/conda/envs/ds/lib/python3.9/site-packages/deepspeed/ops/csrc/transformer/inference/includes -I/opt/conda/envs/ds/lib/python3.9/site-packages/deepspeed/ops/csrc/includes -isystem /opt/conda/envs/ds/lib/python3.9/site-packages/torch/include -isystem /opt/conda/envs/ds/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/envs/ds/lib/python3.9/site-packages/torch/include/TH -isystem /opt/conda/envs/ds/lib/python3.9/site-packages/torch/include/THC -isystem /opt/conda/envs/ds/include -isystem /opt/conda/envs/ds/include/python3.9 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_86,code=compute_86 -c /opt/conda/envs/ds/lib/python3.9/site-packages/deepspeed/ops/csrc/transformer/inference/csrc/softmax.cu -o softmax.cuda.o \n",
      "/opt/conda/envs/ds/lib/python3.9/site-packages/deepspeed/ops/csrc/transformer/inference/csrc/softmax.cu:9:10: fatal error: cuda_profiler_api.h: No such file or directory\n",
      "    9 | #include <cuda_profiler_api.h>\n",
      "      |          ^~~~~~~~~~~~~~~~~~~~~\n",
      "compilation terminated.\n",
      "[2023-01-17 18:00:56,061] [INFO] [server_client.py:117:_wait_until_server_is_live] waiting for server to start...\n",
      "[2/9] /opt/conda/envs/ds/bin/nvcc  -DTORCH_EXTENSION_NAME=transformer_inference -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/opt/conda/envs/ds/lib/python3.9/site-packages/deepspeed/ops/csrc/transformer/inference/includes -I/opt/conda/envs/ds/lib/python3.9/site-packages/deepspeed/ops/csrc/includes -isystem /opt/conda/envs/ds/lib/python3.9/site-packages/torch/include -isystem /opt/conda/envs/ds/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/envs/ds/lib/python3.9/site-packages/torch/include/TH -isystem /opt/conda/envs/ds/lib/python3.9/site-packages/torch/include/THC -isystem /opt/conda/envs/ds/include -isystem /opt/conda/envs/ds/include/python3.9 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_86,code=compute_86 -c /opt/conda/envs/ds/lib/python3.9/site-packages/deepspeed/ops/csrc/transformer/inference/csrc/dequantize.cu -o dequantize.cuda.o \n",
      "[3/9] /opt/conda/envs/ds/bin/nvcc  -DTORCH_EXTENSION_NAME=transformer_inference -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/opt/conda/envs/ds/lib/python3.9/site-packages/deepspeed/ops/csrc/transformer/inference/includes -I/opt/conda/envs/ds/lib/python3.9/site-packages/deepspeed/ops/csrc/includes -isystem /opt/conda/envs/ds/lib/python3.9/site-packages/torch/include -isystem /opt/conda/envs/ds/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/envs/ds/lib/python3.9/site-packages/torch/include/TH -isystem /opt/conda/envs/ds/lib/python3.9/site-packages/torch/include/THC -isystem /opt/conda/envs/ds/include -isystem /opt/conda/envs/ds/include/python3.9 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_86,code=compute_86 -c /opt/conda/envs/ds/lib/python3.9/site-packages/deepspeed/ops/csrc/transformer/inference/csrc/relu.cu -o relu.cuda.o \n",
      "[4/9] /opt/conda/envs/ds/bin/nvcc  -DTORCH_EXTENSION_NAME=transformer_inference -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/opt/conda/envs/ds/lib/python3.9/site-packages/deepspeed/ops/csrc/transformer/inference/includes -I/opt/conda/envs/ds/lib/python3.9/site-packages/deepspeed/ops/csrc/includes -isystem /opt/conda/envs/ds/lib/python3.9/site-packages/torch/include -isystem /opt/conda/envs/ds/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/envs/ds/lib/python3.9/site-packages/torch/include/TH -isystem /opt/conda/envs/ds/lib/python3.9/site-packages/torch/include/THC -isystem /opt/conda/envs/ds/include -isystem /opt/conda/envs/ds/include/python3.9 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_86,code=compute_86 -c /opt/conda/envs/ds/lib/python3.9/site-packages/deepspeed/ops/csrc/transformer/inference/csrc/gelu.cu -o gelu.cuda.o \n",
      "[2023-01-17 18:01:01,065] [INFO] [server_client.py:117:_wait_until_server_is_live] waiting for server to start...\n",
      "[5/9] /opt/conda/envs/ds/bin/nvcc  -DTORCH_EXTENSION_NAME=transformer_inference -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/opt/conda/envs/ds/lib/python3.9/site-packages/deepspeed/ops/csrc/transformer/inference/includes -I/opt/conda/envs/ds/lib/python3.9/site-packages/deepspeed/ops/csrc/includes -isystem /opt/conda/envs/ds/lib/python3.9/site-packages/torch/include -isystem /opt/conda/envs/ds/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/envs/ds/lib/python3.9/site-packages/torch/include/TH -isystem /opt/conda/envs/ds/lib/python3.9/site-packages/torch/include/THC -isystem /opt/conda/envs/ds/include -isystem /opt/conda/envs/ds/include/python3.9 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_86,code=compute_86 -c /opt/conda/envs/ds/lib/python3.9/site-packages/deepspeed/ops/csrc/transformer/inference/csrc/layer_norm.cu -o layer_norm.cuda.o \n",
      "[2023-01-17 18:01:06,071] [INFO] [server_client.py:117:_wait_until_server_is_live] waiting for server to start...\n",
      "[2023-01-17 18:01:11,076] [INFO] [server_client.py:117:_wait_until_server_is_live] waiting for server to start...\n",
      "[2023-01-17 18:01:16,081] [INFO] [server_client.py:117:_wait_until_server_is_live] waiting for server to start...\n",
      "[6/9] c++ -MMD -MF pt_binding.o.d -DTORCH_EXTENSION_NAME=transformer_inference -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/opt/conda/envs/ds/lib/python3.9/site-packages/deepspeed/ops/csrc/transformer/inference/includes -I/opt/conda/envs/ds/lib/python3.9/site-packages/deepspeed/ops/csrc/includes -isystem /opt/conda/envs/ds/lib/python3.9/site-packages/torch/include -isystem /opt/conda/envs/ds/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/envs/ds/lib/python3.9/site-packages/torch/include/TH -isystem /opt/conda/envs/ds/lib/python3.9/site-packages/torch/include/THC -isystem /opt/conda/envs/ds/include -isystem /opt/conda/envs/ds/include/python3.9 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -c /opt/conda/envs/ds/lib/python3.9/site-packages/deepspeed/ops/csrc/transformer/inference/csrc/pt_binding.cpp -o pt_binding.o \n",
      "ninja: build stopped: subcommand failed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/ds/lib/python3.9/site-packages/torch/utils/cpp_extension.py\", line 1808, in _run_ninja_build\n",
      "    subprocess.run(\n",
      "  File \"/opt/conda/envs/ds/lib/python3.9/subprocess.py\", line 528, in run\n",
      "    raise CalledProcessError(retcode, process.args,\n",
      "subprocess.CalledProcessError: Command '['ninja', '-v']' returned non-zero exit status 1.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/ds/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/envs/ds/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/envs/ds/lib/python3.9/site-packages/mii/launch/multi_gpu_server.py\", line 70, in <module>\n",
      "    main()\n",
      "  File \"/opt/conda/envs/ds/lib/python3.9/site-packages/mii/launch/multi_gpu_server.py\", line 56, in main\n",
      "    inference_pipeline = load_models(task_name=args.task_name,\n",
      "  File \"/opt/conda/envs/ds/lib/python3.9/site-packages/mii/models/load_models.py\", line 83, in load_models\n",
      "    engine = deepspeed.init_inference(getattr(inference_pipeline,\n",
      "  File \"/opt/conda/envs/ds/lib/python3.9/site-packages/deepspeed/__init__.py\", line 311, in init_inference\n",
      "    engine = InferenceEngine(model, config=ds_inference_config)\n",
      "  File \"/opt/conda/envs/ds/lib/python3.9/site-packages/deepspeed/inference/engine.py\", line 124, in __init__\n",
      "    self._apply_injection_policy(config)\n",
      "  File \"/opt/conda/envs/ds/lib/python3.9/site-packages/deepspeed/inference/engine.py\", line 342, in _apply_injection_policy\n",
      "    generic_injection(self.module,\n",
      "  File \"/opt/conda/envs/ds/lib/python3.9/site-packages/deepspeed/module_inject/replace_module.py\", line 284, in generic_injection\n",
      "    _replace_module(sub_module, policy)\n",
      "  File \"/opt/conda/envs/ds/lib/python3.9/site-packages/deepspeed/module_inject/replace_module.py\", line 278, in _replace_module\n",
      "    _replace_module(child, policy)\n",
      "  File \"/opt/conda/envs/ds/lib/python3.9/site-packages/deepspeed/module_inject/replace_module.py\", line 278, in _replace_module\n",
      "    _replace_module(child, policy)\n",
      "  File \"/opt/conda/envs/ds/lib/python3.9/site-packages/deepspeed/module_inject/replace_module.py\", line 278, in _replace_module\n",
      "    _replace_module(child, policy)\n",
      "  [Previous line repeated 3 more times]\n",
      "  File \"/opt/conda/envs/ds/lib/python3.9/site-packages/deepspeed/module_inject/replace_module.py\", line 280, in _replace_module\n",
      "    replaced_module = new_policies[child.__class__](child,\n",
      "  File \"/opt/conda/envs/ds/lib/python3.9/site-packages/deepspeed/module_inject/replace_module.py\", line 217, in replace_attn\n",
      "    attn_module = DeepSpeedDiffusersAttention(config)\n",
      "  File \"/opt/conda/envs/ds/lib/python3.9/site-packages/deepspeed/ops/transformer/inference/diffusers_attention.py\", line 151, in __init__\n",
      "    inference_cuda_module = builder.load()\n",
      "  File \"/opt/conda/envs/ds/lib/python3.9/site-packages/deepspeed/ops/op_builder/builder.py\", line 460, in load\n",
      "    return self.jit_load(verbose)\n",
      "  File \"/opt/conda/envs/ds/lib/python3.9/site-packages/deepspeed/ops/op_builder/builder.py\", line 495, in jit_load\n",
      "    op_module = load(\n",
      "  File \"/opt/conda/envs/ds/lib/python3.9/site-packages/torch/utils/cpp_extension.py\", line 1202, in load\n",
      "    return _jit_compile(\n",
      "  File \"/opt/conda/envs/ds/lib/python3.9/site-packages/torch/utils/cpp_extension.py\", line 1425, in _jit_compile\n",
      "    _write_ninja_file_and_build_library(\n",
      "  File \"/opt/conda/envs/ds/lib/python3.9/site-packages/torch/utils/cpp_extension.py\", line 1537, in _write_ninja_file_and_build_library\n",
      "    _run_ninja_build(\n",
      "  File \"/opt/conda/envs/ds/lib/python3.9/site-packages/torch/utils/cpp_extension.py\", line 1824, in _run_ninja_build\n",
      "    raise RuntimeError(message) from e\n",
      "RuntimeError: Error building extension 'transformer_inference'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-01-17 18:01:21,087] [INFO] [server_client.py:117:_wait_until_server_is_live] waiting for server to start...\n",
      "[2023-01-17 18:01:21,594] [INFO] [launch.py:318:sigkill_handler] Killing subprocess 33806\n",
      "[2023-01-17 18:01:21,595] [ERROR] [launch.py:324:sigkill_handler] ['/opt/conda/envs/ds/bin/python', '-m', 'mii.launch.multi_gpu_server', '--task-name', 'text-to-image', '--model', 'runwayml/stable-diffusion-v1-5', '--model-path', '/tmp/mii_models', '--port', '50050', '--ds-optimize', '--provider', 'diffusers', '--config', 'eyJ0ZW5zb3JfcGFyYWxsZWwiOiAxLCAicG9ydF9udW1iZXIiOiA1MDA1MCwgImR0eXBlIjogInRvcmNoLmZsb2F0MTYiLCAibG9hZF93aXRoX3N5c19tZW0iOiBmYWxzZSwgImVuYWJsZV9jdWRhX2dyYXBoIjogZmFsc2UsICJjaGVja3BvaW50X2RpY3QiOiBudWxsLCAiZGVwbG95X3JhbmsiOiBbMF0sICJ0b3JjaF9kaXN0X3BvcnQiOiAyOTUwMCwgImhmX2F1dGhfdG9rZW4iOiBudWxsLCAicmVwbGFjZV93aXRoX2tlcm5lbF9pbmplY3QiOiB0cnVlLCAicHJvZmlsZV9tb2RlbF90aW1lIjogZmFsc2UsICJza2lwX21vZGVsX2NoZWNrIjogZmFsc2V9'] exits with return code = 1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "server crashed for some reason, unable to proceed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmii\u001b[39;00m\n\u001b[1;32m      3\u001b[0m mii_config \u001b[39m=\u001b[39m {\n\u001b[1;32m      4\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mfp16\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m }\n\u001b[0;32m----> 7\u001b[0m mii\u001b[39m.\u001b[39;49mdeploy(task\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtext-to-image\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      8\u001b[0m            model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mrunwayml/stable-diffusion-v1-5\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      9\u001b[0m            deployment_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msd_deploy\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     10\u001b[0m            mii_config\u001b[39m=\u001b[39;49mmii_config)\n",
      "File \u001b[0;32m/opt/conda/envs/ds/lib/python3.9/site-packages/mii/deployment.py:114\u001b[0m, in \u001b[0;36mdeploy\u001b[0;34m(task, model, deployment_name, deployment_type, model_path, enable_deepspeed, enable_zero, ds_config, mii_config, version)\u001b[0m\n\u001b[1;32m    112\u001b[0m     _deploy_aml(deployment_name\u001b[39m=\u001b[39mdeployment_name, model_name\u001b[39m=\u001b[39mmodel, version\u001b[39m=\u001b[39mversion)\n\u001b[1;32m    113\u001b[0m \u001b[39melif\u001b[39;00m deployment_type \u001b[39m==\u001b[39m DeploymentType\u001b[39m.\u001b[39mLOCAL:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m _deploy_local(deployment_name, model_path\u001b[39m=\u001b[39;49mmodel_path)\n\u001b[1;32m    115\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnknown deployment type: \u001b[39m\u001b[39m{\u001b[39;00mdeployment_type\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/ds/lib/python3.9/site-packages/mii/deployment.py:120\u001b[0m, in \u001b[0;36m_deploy_local\u001b[0;34m(deployment_name, model_path)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_deploy_local\u001b[39m(deployment_name, model_path):\n\u001b[0;32m--> 120\u001b[0m     mii\u001b[39m.\u001b[39;49mutils\u001b[39m.\u001b[39;49mimport_score_file(deployment_name)\u001b[39m.\u001b[39;49minit()\n",
      "File \u001b[0;32m/tmp/mii_cache/sd_deploy/score.py:30\u001b[0m, in \u001b[0;36minit\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39massert\u001b[39;00m task \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mThe task name should be set before calling init\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     29\u001b[0m \u001b[39mglobal\u001b[39;00m model\n\u001b[0;32m---> 30\u001b[0m model \u001b[39m=\u001b[39m mii\u001b[39m.\u001b[39;49mMIIServerClient(task,\n\u001b[1;32m     31\u001b[0m                             model_name,\n\u001b[1;32m     32\u001b[0m                             model_path,\n\u001b[1;32m     33\u001b[0m                             ds_optimize\u001b[39m=\u001b[39;49mconfigs[mii\u001b[39m.\u001b[39;49mconstants\u001b[39m.\u001b[39;49mENABLE_DEEPSPEED_KEY],\n\u001b[1;32m     34\u001b[0m                             ds_zero\u001b[39m=\u001b[39;49mconfigs[mii\u001b[39m.\u001b[39;49mconstants\u001b[39m.\u001b[39;49mENABLE_DEEPSPEED_ZERO_KEY],\n\u001b[1;32m     35\u001b[0m                             ds_config\u001b[39m=\u001b[39;49mconfigs[mii\u001b[39m.\u001b[39;49mconstants\u001b[39m.\u001b[39;49mDEEPSPEED_CONFIG_KEY],\n\u001b[1;32m     36\u001b[0m                             mii_configs\u001b[39m=\u001b[39;49mconfigs[mii\u001b[39m.\u001b[39;49mconstants\u001b[39m.\u001b[39;49mMII_CONFIGS_KEY],\n\u001b[1;32m     37\u001b[0m                             use_grpc_server\u001b[39m=\u001b[39;49muse_grpc_server,\n\u001b[1;32m     38\u001b[0m                             initialize_grpc_client\u001b[39m=\u001b[39;49minitialize_grpc_client)\n",
      "File \u001b[0;32m/opt/conda/envs/ds/lib/python3.9/site-packages/mii/server_client.py:92\u001b[0m, in \u001b[0;36mMIIServerClient.__init__\u001b[0;34m(self, task_name, model_name, model_path, ds_optimize, ds_zero, ds_config, mii_configs, initialize_service, initialize_grpc_client, use_grpc_server)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initialize_service(model_name,\n\u001b[1;32m     86\u001b[0m                                             model_path,\n\u001b[1;32m     87\u001b[0m                                             ds_optimize,\n\u001b[1;32m     88\u001b[0m                                             ds_zero,\n\u001b[1;32m     89\u001b[0m                                             ds_config,\n\u001b[1;32m     90\u001b[0m                                             mii_configs)\n\u001b[1;32m     91\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_grpc_server:\n\u001b[0;32m---> 92\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wait_until_server_is_live()\n\u001b[1;32m     94\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitialize_grpc_client \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_grpc_server:\n\u001b[1;32m     95\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstubs \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m/opt/conda/envs/ds/lib/python3.9/site-packages/mii/server_client.py:115\u001b[0m, in \u001b[0;36mMIIServerClient._wait_until_server_is_live\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    113\u001b[0m process_alive \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_server_process_alive()\n\u001b[1;32m    114\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m process_alive:\n\u001b[0;32m--> 115\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mserver crashed for some reason, unable to proceed\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    116\u001b[0m time\u001b[39m.\u001b[39msleep(\u001b[39m4\u001b[39m)\n\u001b[1;32m    117\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mwaiting for server to start...\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: server crashed for some reason, unable to proceed"
     ]
    }
   ],
   "source": [
    "import mii\n",
    "\n",
    "mii_config = {\n",
    "    \"dtype\": \"fp16\",\n",
    "}\n",
    "\n",
    "mii.deploy(task='text-to-image',\n",
    "           model=\"runwayml/stable-diffusion-v1-5\",\n",
    "           deployment_name=\"sd_deploy\",\n",
    "           mii_config=mii_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mii\n",
    "generator = mii.mii_query_handle(\"sd_deploy\")\n",
    "prompt = \"a photo of an astronaut riding a horse on mars\"\n",
    "image = generator.query({'query': prompt}).images[0]\n",
    "image.save(\"horse-on-mars.png\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vanilla pipeline: P95 latency (seconds) - 3.00; Average latency (seconds) - 3.00 +\\- 0.00;\n"
     ]
    }
   ],
   "source": [
    "from time import perf_counter\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def measure_latency(pipe, prompt):\n",
    "    latencies = []\n",
    "    # warm up\n",
    "    pipe.set_progress_bar_config(disable=True)\n",
    "    for _ in range(2):\n",
    "        _ =  pipe(prompt)\n",
    "    # Timed run\n",
    "    for _ in range(10):\n",
    "        start_time = perf_counter()\n",
    "        _ = pipe(prompt,   \n",
    "                 num_inference_steps=25,\n",
    "                guidance_scale=7.5,\n",
    "                num_images_per_prompt=1,\n",
    "                )\n",
    "        latency = perf_counter() - start_time\n",
    "        latencies.append(latency)\n",
    "    # Compute run statistics\n",
    "    time_avg_s = np.mean(latencies)\n",
    "    time_std_s = np.std(latencies)\n",
    "    time_p95_s = np.percentile(latencies,95)\n",
    "    return f\"P95 latency (seconds) - {time_p95_s:.2f}; Average latency (seconds) - {time_avg_s:.2f} +\\- {time_std_s:.2f};\", time_p95_s\n",
    "\n",
    "\n",
    "prompt = \"a photo of an astronaut riding a horse on mars\"\n",
    "\n",
    "vanilla_results = measure_latency(pipe, prompt)\n",
    "\n",
    "print(f\"Vanilla pipeline: {vanilla_results[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bf394f40c161475072bcd2f2176b2d8c08ea2199a743f7ae9cb490daa062bb58"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
